{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reader: the dataset was too large to upload to Github. \n",
    "#We used the Expedia Challenge dataset, available as a free download from Kaggle\n",
    "\n",
    "import pandas as pd\n",
    "import gzip \n",
    "import numpy as np\n",
    "%run map.py\n",
    "\n",
    "with open('train.csv', 'rb') as fd:\n",
    "    gzip_fd = gzip.GzipFile(fileobj=fd)\n",
    "    data = pd.read_csv(gzip_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssr = .01 #subsampling rate\n",
    "N = data.shape[0]\n",
    "\n",
    "train = data.sample(n=int(ssr*N), axis=0, replace=False)\n",
    "test = data.sample(n=int(.25*ssr*N), axis=0, replace=False)\n",
    "\n",
    "train_users = train['user_id'].as_matrix()\n",
    "train_clusters = train['hotel_cluster'].as_matrix()\n",
    "train_ratings = train['is_booking'].as_matrix()\n",
    "\n",
    "test_users  = test['user_id'].as_matrix()\n",
    "test_clusters  = test['hotel_cluster'].as_matrix()\n",
    "test_ratings = test['is_booking'].as_matrix()\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code here is by Kyle. For the theory, see Salakhutdinov et al., 2007: RBMs for collaborative filtering\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import copy\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class Collaborative_RBM():\n",
    "    \n",
    "    def __init__(self,M,N,K,F,W,b_features,b_movies,V_all,H_all):\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "        self.K = K\n",
    "        self.F = F\n",
    "        self.W = W\n",
    "        self.b_features = b_features\n",
    "        self.b_movies = b_movies\n",
    "        self.V_all = V_all\n",
    "        self.H_all = H_all\n",
    "   \n",
    "    @staticmethod\n",
    "    def softmax(arr):\n",
    "        return np.exp(arr)/np.sum(np.exp(arr))\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(val):\n",
    "        return 1/(1 + np.exp(-val))\n",
    "\n",
    "    def p_v_given_h(self, h):\n",
    "        vf = lambda l: self.b_movies[:,l] + np.dot(h, self.W[:,:,l].T)\n",
    "        V_unnormalized = np.exp(np.array([vf(l) for l in range(self.K)])).T\n",
    "        V = (V_unnormalized.T/np.sum(V_unnormalized, axis=1)).T\n",
    "        return V\n",
    "    \n",
    "    def confidence_v_given_h(self, h):\n",
    "        vf = lambda l: self.b_movies[:,l] + np.dot(h, self.W[:,:,l].T)\n",
    "        return np.exp(np.array([vf(l) for l in range(self.K)])).T\n",
    "\n",
    "    def p_h_given_V(self, V):\n",
    "        vf = np.vectorize(lambda j : self.b_features[j] + np.sum(np.multiply(V, self.W[:,j])))\n",
    "        return self.sigmoid(vf(np.arange(0,self.F)))    \n",
    "\n",
    "    def vij_exp_data(self):\n",
    "        deltaW_data = np.zeros((self.M,self.F,self.K))\n",
    "        for u in range(self.N):\n",
    "            V = np.vstack([np.zeros(K), np.eye(K)])[self.V_all[u].toarray()[0]]\n",
    "            deltaW_data += (np.multiply.outer(V, self.p_h_given_V(V)).transpose(0,2,1))/self.N\n",
    "        return deltaW_data\n",
    "\n",
    "    def vij_exp_T(self,T):\n",
    "        V_T = copy.copy(self.V_all)\n",
    "        H_T = np.zeros((self.N,self.F))\n",
    "        deltaW_data = np.zeros((self.M,self.F,self.K))\n",
    "\n",
    "        vf1 = np.vectorize(lambda p : np.random.binomial(1,p))\n",
    "        vf2 = lambda row : np.vstack([np.zeros(self.K), np.eye(self.K)])[np.random.choice(range(self.K), 1, list(row))]\n",
    "\n",
    "        for epoch in range(T):\n",
    "            V_Tp1 = copy.copy(V_T)\n",
    "            H_Tp1 = copy.copy(H_T)\n",
    "\n",
    "            #sample hidden states \n",
    "            for u in range(self.N):\n",
    "                V = np.vstack([np.zeros(K), np.eye(K)])[V_T[u].toarray()[0]]\n",
    "                H_Tp1[u] = vf1(self.p_h_given_V(V))\n",
    "\n",
    "            #sample visible features\n",
    "            for u in range(self.N):\n",
    "                V_hot = self.p_v_given_h(H_Tp1[u])\n",
    "                V_labels = np.zeros((1,self.M))\n",
    "                for i in range(self.M):\n",
    "                    V_labels[:,i] = vf2(V_hot[i])\n",
    "                V_Tp1[u] = csr_matrix(V_labels)\n",
    "\n",
    "            V_T = V_Tp1\n",
    "            H_T = H_Tp1\n",
    "\n",
    "            for u in range(self.N):\n",
    "                V = np.vstack([np.zeros(K), np.eye(K)])[V_T[u].toarray()[0]]\n",
    "                deltaW_data += (np.multiply.outer(V, H_T[u]).transpose(0,2,1))/(T*self.N)\n",
    "\n",
    "            V_T = V_Tp1\n",
    "            H_T = H_Tp1\n",
    "        return deltaW_data\n",
    "    \n",
    "    def train(self, epochs, lr, gs_T):\n",
    "        for epoch in range(epochs):            \n",
    "            print(epoch)\n",
    "            self.W += lr*(self.vij_exp_data() - self.vij_exp_T(gs_T))\n",
    "            \n",
    "    def pred(self):\n",
    "        vf1 = np.vectorize(lambda p : np.random.binomial(1,p))\n",
    "        vf2 = lambda row : np.vstack([np.zeros(self.K), np.eye(self.K)])[np.random.choice(range(self.K), 1, list(row))]\n",
    "        \n",
    "        H_pred = copy.copy(self.H_all)\n",
    "        for u in range(self.N):\n",
    "            V = np.vstack([np.zeros(K), np.eye(K)])[self.V_all[u].toarray()[0]]\n",
    "            H_pred[u] = vf1(self.p_h_given_V(V))\n",
    "                    \n",
    "        V_pred = csr_matrix(np.zeros((N,M)))\n",
    "        for u in range(self.N):\n",
    "            V_confidences = self.confidence_v_given_h(H_pred[u]).T\n",
    "            V_pred[u] = csr_matrix(V_confidences)\n",
    "            \n",
    "        return V_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12309, 35748,  5329, ..., 16027,  7249, 33404])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some helper functions\n",
    "\n",
    "def compress(l):\n",
    "    #recoverably sends an int list to an int list with max(compress(l)) = len(set(l)) - 1\n",
    "    d = {}\n",
    "    for i,j in enumerate(l):\n",
    "        if j in d:\n",
    "            d[j] += [i]\n",
    "        else:\n",
    "            d[j] = [i]\n",
    "    arr = np.argsort(np.argsort(l))\n",
    "    for j in d:\n",
    "        for i in d[j]:\n",
    "            arr[i] = arr[d[j][0]]\n",
    "    return arr\n",
    "\n",
    "def blowup(l, orig):\n",
    "    #inverse of compress when passed original list orig\n",
    "    return orig[np.argsort(orig)[l]]\n",
    "\n",
    "def mapatk(k, probas):\n",
    "    y_pred = (np.argsort(-probas, axis=1)[:, k:]).tolist()\n",
    "\n",
    "    y_test_list = np.array([train_clusters]).T.tolist()\n",
    "    return np.mean(mapk(y_test_list, y_pred, k))\n",
    "\n",
    "def mapk(actual, predicted, k):\n",
    "    return [apk(a,p,k) for a,p in zip(actual, predicted)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compressed_users = compress(train_users)\n",
    "compressed_users_valid = compress(test_users)\n",
    "\n",
    "N = compressed_users.shape[0]\n",
    "Np = compressed_users_valid.shape[0]\n",
    "M = max(train_clusters)+1\n",
    "K = 1\n",
    "F = 2\n",
    "V_all_dense = np.zeros((N,M), dtype=np.int8)\n",
    "for u in compressed_users:\n",
    "    il = np.where(compressed_users==u)[0]\n",
    "    V_all_dense[u][train_clusters[il]] = 1\n",
    "V_all = csr_matrix(V_all_dense)\n",
    "\n",
    "V_all_valid_dense = np.zeros((Np,M), dtype=np.int8)\n",
    "for u in compressed_users_valid:\n",
    "    il = np.where(compressed_users_valid==u)[0]\n",
    "    V_all_dense[u][test_clusters[il]] = 1\n",
    "V_all_valid = csr_matrix(V_all_valid_dense)\n",
    "\n",
    "H_all = np.zeros((N,F))\n",
    "\n",
    "W = np.random.normal(size = (M, F, K))\n",
    "b_features = np.zeros((F))\n",
    "b_movies = np.zeros((M,K))\n",
    "\n",
    "model = Collaborative_RBM(K=K, N=N, M=M, F=F, H_all=H_all, V_all=V_all, W=W, b_features=b_features, b_movies=b_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_valid = Collaborative_RBM(K=K, N=V_all_valid.shape[0], M=M, F=F, H_all=H_all, V_all=V_all_valid, W=model.W, b_features=b_features, b_movies=b_movies)\n",
    "pred = model_valid.pred().toarray()\n",
    "\n",
    "y_pred = np.flip((np.argsort(pred, axis=1))[:, -5:], axis=1).tolist()\n",
    "y_test_list = np.array([test_clusters]).T.tolist()\n",
    "\n",
    "np.mean(mapk(y_test_list, y_pred2, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
